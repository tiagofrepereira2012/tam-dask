{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask delay\n",
    "\n",
    "Not everything reduces to what is inside numpy (dask array API).\n",
    "\n",
    "Dask delayed allows you to:\n",
    "  1. Do custom computations with regular python code\n",
    "  2. Scale them up to heterogeneous clusters\n",
    "\n",
    "Let's setup the same infrastructure as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local client\n",
    "from dask import delayed\n",
    "from dask.distributed import Client\n",
    "n_workers = 30\n",
    "\n",
    "\n",
    "def scale_to_sge(n_workers):\n",
    "    queue=\"q_1day\"\n",
    "    queue_resource_spec=\"q_1day=TRUE\"\n",
    "    memory=\"4GB\"\n",
    "    sge_log= \"./logs\"\n",
    "    from dask_jobqueue import SGECluster\n",
    "    cluster = SGECluster(queue=queue, memory=memory, cores=1, processes=1,\n",
    "              log_directory=sge_log,\n",
    "              local_directory=sge_log,\n",
    "              resource_spec=queue_resource_spec\n",
    "              )\n",
    "    cluster.scale_up(n_workers)\n",
    "    return Client(cluster)  # start local workers as threads\n",
    "\n",
    "# Local client\n",
    "#client = Client(n_workers=n_workers)\n",
    "\n",
    "# SGE client\n",
    "client = scale_to_sge(n_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an GMM-UBM distributed using Dask\n",
    "\n",
    "In the example below dask delayed is used to build a simple pipeline to train GMM-UBM with speaker data.\n",
    "The pipeline is pretty simple and can be split in the parts.\n",
    "\n",
    "## Feature extraction.\n",
    "\n",
    "For each audio file the following steps are piped using dask delayed:\n",
    "\n",
    "  1. File opening (using scipy)\n",
    "  2. Training and detection segments that contains audio (bob.bio.spear.preprocessor.Energy_2Gauss)\n",
    "  3. Extraction of MFCC features (bob.bio.spear.extractor.Cepstral)\n",
    " \n",
    "## GMM training\n",
    "\n",
    "Once we have the MFCCs for all audio file, we can run the EM algorithm to train the GMM.\n",
    "In this example a GMM is initialized from some previous GMM (just for the sake of the example).\n",
    "Furthermore, only the GMM means are updated during the mstep.\n",
    "\n",
    "For GMM training, for each EM iteration, the following steps are piped using dask delays:\n",
    "\n",
    "  1. E-step. For each block of MFCSS compute the posterior probabilities. Those posteriors are accumulated using two statistics. The first one, called zeroth order, is the simple summation of the posteriors. The second one, called first order, is the dot product between zeroth order and the input MFCCs data.\n",
    "  2. Accumulation. The statistics from the previous step is accumulated using the (everything is summed)\n",
    "  3. M-step. The recomputation of the means.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# fetching the data\n",
    "import glob\n",
    "import os\n",
    "\n",
    "##### ADD YOUR PATH HERE. \n",
    "##### I CAN'T SHARE ONLINE A PATH FROM OUR SHARED FILE SYSTEM ##################\n",
    "PATH_TO_VOX_FORGE = \"\"\n",
    "paths = glob.glob(os.path.join(PATH_TO_VOX_FORGE, \"16kHz_16bit/*/wav/*.wav\"))\n",
    "####################\n",
    "\n",
    "\n",
    "import bob.bio.spear\n",
    "import scipy\n",
    "import numpy\n",
    "import bob.learn.em\n",
    "import bob.io.base\n",
    "\n",
    "em_iterations = 5\n",
    "sample_rate = 16000\n",
    "n_files = 2000\n",
    "\n",
    "preprocessor = bob.bio.spear.preprocessor.Energy_2Gauss()\n",
    "\n",
    "extractor = bob.bio.spear.extractor.Cepstral()\n",
    "\n",
    "def read_audio(path):\n",
    "    _, audio = scipy.io.wavfile.read(path)\n",
    "    audio = numpy.cast['float'](audio)\n",
    "    return audio\n",
    "\n",
    "def preprocess(data, preprocessor, sample_rate=16000):\n",
    "    _,_,preprocessed = preprocessor((sample_rate, data))\n",
    "    return preprocessed\n",
    "\n",
    "def extract(data, vad_data, extractor, sample_rate=16000):\n",
    "    extracted = extractor((sample_rate, data, vad_data))\n",
    "    return extracted\n",
    "\n",
    "\n",
    "\n",
    "# GMM INITIALIZATION\n",
    "from gmm_steps import e_step, m_step, acc_stats\n",
    "\n",
    "# Initialization of the champions\n",
    "# THE GMM has 2 gaussians\n",
    "gmm_initialization =  bob.learn.em.GMMMachine(bob.io.base.HDF5File(\"Projector.hdf5\"))\n",
    "weights = gmm_initialization.weights\n",
    "variances = gmm_initialization.variances\n",
    "means = gmm_initialization.means\n",
    "#####\n",
    "\n",
    "\n",
    "# First part of the graph.\n",
    "# Extract features\n",
    "mfccs = []\n",
    "for p in paths[0:n_files]:\n",
    "    \n",
    "    data = delayed(read_audio)(p)\n",
    "    \n",
    "    preprocessed = delayed(preprocess)(data, preprocessor)    \n",
    "    extracted = delayed(extract)(data, preprocessed, extractor)\n",
    "\n",
    "    mfccs.append(extracted)\n",
    "    \n",
    "# Second part of the graph\n",
    "# EM\n",
    "for i in range(em_iterations):\n",
    "    gmm_stats = []\n",
    "    for mfcc in mfccs:                    \n",
    "        gmm_stats.append(delayed(e_step)(mfcc, weights, means, variances))\n",
    "    \n",
    "    acc_gmm_stats = delayed(acc_stats)(gmm_stats)\n",
    "    means = delayed(m_step)(acc_gmm_stats)\n",
    "\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have the graph. We execute it\n",
    "\n",
    "Also, try to check what is in http://localhost:8787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Means at step [0]\")\n",
    "print(gmm_initialization.means)\n",
    "print(\"##############\")\n",
    "print(\"Means at step [n]\")\n",
    "print(means.compute(scheduler=client))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Always shutdown your client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
